{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf5459f-b6f0-4372-9680-c4180f912490",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1df7b81f-c295-46ff-bee6-9a8bc244fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab4ff8c-4202-4ac8-8c6b-111f28e1a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from os.path import join as path_join\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a206d9-ee3f-4b4b-8192-65f6757e4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"../dataset_v1/data/tglang_dataset/Forest_Train.parquet\")\n",
    "eval_path  = Path(\"../dataset_v1/data/tglang_dataset/Eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4cf11d-bc4d-44bf-b2d7-f5b210c32b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, max_samples_per_class=1000):\n",
    "    df = pd.read_parquet(path)\\\n",
    "            [[\"code\", \"tglang\", \"target\"]]\\\n",
    "            .reset_index()\\\n",
    "            .groupby(\"tglang\")\\\n",
    "            .apply(\n",
    "                lambda x: x[[\"target\", \"code\"]].sample(n=min(max_samples_per_class, x.shape[0]), random_state=137)\n",
    "            )\\\n",
    "            .reset_index()\\\n",
    "            [[\"code\", \"tglang\", \"target\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2904ccf1-95cf-4fee-bc62-336b302e82f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uri',\n",
       " 'last',\n",
       " 'library',\n",
       " 'geoip_city_continent_code',\n",
       " 'rp',\n",
       " 'double',\n",
       " 'tab',\n",
       " 'tcpinfo_rtt',\n",
       " 'mode',\n",
       " 'div',\n",
       " 'lua_iscfunction',\n",
       " 'lua_checkstack',\n",
       " 'error',\n",
       " 'underline',\n",
       " 'embed',\n",
       " 'EXISTS',\n",
       " 'upstream_bytes_received',\n",
       " 'var',\n",
       " 'lua_gettop',\n",
       " 'Protocol',\n",
       " 'int',\n",
       " 'li',\n",
       " 'auto',\n",
       " 'proxy_protocol_server_port',\n",
       " 'fileprivate',\n",
       " 'bool',\n",
       " '__property',\n",
       " 'cushort',\n",
       " 'dyn',\n",
       " 'clone',\n",
       " 'time_iso8601',\n",
       " 'fileID',\n",
       " 'CHECK',\n",
       " 'snap',\n",
       " 'include_once',\n",
       " 'alias',\n",
       " 'out',\n",
       " 'background',\n",
       " 'on',\n",
       " 'behavior',\n",
       " 'transient',\n",
       " 'mut',\n",
       " 'left',\n",
       " 'bdi',\n",
       " 'otel_trace_id',\n",
       " 'ssl_client_i_dn_legacy',\n",
       " 'builder',\n",
       " 'trait',\n",
       " 'overscroll',\n",
       " 'modern_browser',\n",
       " 'macro',\n",
       " 'redo',\n",
       " 'integer',\n",
       " 'ulimit',\n",
       " 'begin',\n",
       " 'connections_writing',\n",
       " 'trap',\n",
       " 'arg_',\n",
       " 'ssl_client_s_dn_legacy',\n",
       " '__forceinline',\n",
       " '__m128',\n",
       " 'TRUNCATE',\n",
       " 'search',\n",
       " 'spacing',\n",
       " 'memcached_key',\n",
       " 'block',\n",
       " 'hr',\n",
       " 'sent_trailer_',\n",
       " 'ssl_server_name',\n",
       " 'uint32',\n",
       " 'table',\n",
       " 'hanging',\n",
       " 'ligatures',\n",
       " 'geoip_city',\n",
       " 'cont',\n",
       " 'crate',\n",
       " 'union',\n",
       " 'gradient',\n",
       " 'nonlocal',\n",
       " 'as',\n",
       " 'EXPOSE',\n",
       " 'forall',\n",
       " 'or',\n",
       " 'and',\n",
       " 'retry',\n",
       " 'lua_getmetatable',\n",
       " 'reflexpr',\n",
       " 'b',\n",
       " 'settings',\n",
       " 'source',\n",
       " 'val',\n",
       " 'uint8',\n",
       " 'fixed',\n",
       " '__m64',\n",
       " '__declspec',\n",
       " 'EXEC',\n",
       " 'server_name',\n",
       " '__TRAIT__',\n",
       " 'session_log_id',\n",
       " 'int16',\n",
       " 'mqtt_preread_clientid',\n",
       " 'connection_requests',\n",
       " 'small',\n",
       " 'body',\n",
       " 'legend',\n",
       " 'ssl_protocol',\n",
       " 'events',\n",
       " 'jwt_claim_',\n",
       " 'require',\n",
       " 'fastcgi_script_name',\n",
       " 'rem',\n",
       " 'concept',\n",
       " '__abstract',\n",
       " '__if_exists',\n",
       " 'become',\n",
       " 'geoip_postal_code',\n",
       " 'FROM',\n",
       " 'from',\n",
       " '@media',\n",
       " 'letter',\n",
       " 'distance',\n",
       " 'const',\n",
       " 'Any',\n",
       " 'LEFT',\n",
       " 'LIKE',\n",
       " '__sptre',\n",
       " 'content',\n",
       " 'implements',\n",
       " 'throw',\n",
       " 'WORKDIR',\n",
       " 'native',\n",
       " 'real',\n",
       " 'size',\n",
       " 'connections_reading',\n",
       " 'upstream_addr',\n",
       " 'bitand',\n",
       " 'case',\n",
       " 'frame',\n",
       " 'reset',\n",
       " 'lazy',\n",
       " 'gzip_ratio',\n",
       " '__noop',\n",
       " 'max',\n",
       " 'CMD',\n",
       " 'NSNumber',\n",
       " 'except',\n",
       " '__delegate',\n",
       " 'part',\n",
       " 'True',\n",
       " 'overflow',\n",
       " '__unaligned',\n",
       " 'bottom',\n",
       " 'longword',\n",
       " 'geoip_country_code3',\n",
       " 'count',\n",
       " 'param',\n",
       " 'internal',\n",
       " 'value class',\n",
       " 'secure_link_expires',\n",
       " 'didSet',\n",
       " 'fulfill',\n",
       " '__LINE__',\n",
       " 'SELECT',\n",
       " 'basis',\n",
       " 'indent',\n",
       " 'readwrite',\n",
       " 'pointer',\n",
       " 'h1',\n",
       " 'unsafe',\n",
       " 'i',\n",
       " 'tfoot',\n",
       " 'CASE',\n",
       " 'article',\n",
       " 'pass',\n",
       " 'frameset',\n",
       " 'INSERT',\n",
       " 'wbr',\n",
       " 'template',\n",
       " '__cdecl',\n",
       " 'ruby',\n",
       " 'with',\n",
       " 'unowned',\n",
       " 'MAINTAINER',\n",
       " 'upstream_status',\n",
       " 'endwhile',\n",
       " 'fileLiteral',\n",
       " 'value struct',\n",
       " 'flow',\n",
       " 'specified',\n",
       " 'lock',\n",
       " 'summary',\n",
       " 'col',\n",
       " 'header',\n",
       " 'KEY',\n",
       " 'connections_waiting',\n",
       " 'cells',\n",
       " 'decoration',\n",
       " 'dfn',\n",
       " 'float',\n",
       " 'annotation',\n",
       " 'read',\n",
       " 'update',\n",
       " 'def',\n",
       " 'proxy_host',\n",
       " 'rt',\n",
       " '__int16',\n",
       " 'bytes_sent',\n",
       " 'caption',\n",
       " 'while',\n",
       " 'atomic_commit',\n",
       " 'filePath',\n",
       " 'hidden',\n",
       " 'await',\n",
       " 'return',\n",
       " 'dialog',\n",
       " 'ssl_curves',\n",
       " 'static_cast',\n",
       " '__multiple_inheritance',\n",
       " 'iteration',\n",
       " 'REPLACE',\n",
       " 'ALTER',\n",
       " 'bidi',\n",
       " 'actual',\n",
       " 'open',\n",
       " 'unless',\n",
       " 'perspective',\n",
       " 'view',\n",
       " 'implicit',\n",
       " 'desc',\n",
       " '__alignof',\n",
       " 'encoding',\n",
       " 'white',\n",
       " 'kerning',\n",
       " 'outer',\n",
       " 'upstream_http_',\n",
       " 'ul',\n",
       " 'generic',\n",
       " 'tcpinfo_snd_cwnd',\n",
       " 'cuint',\n",
       " 'xmlns',\n",
       " 'switch',\n",
       " 'proxy_port',\n",
       " 'fun',\n",
       " 'emphasis',\n",
       " 'deinit',\n",
       " 'distinct',\n",
       " 'clong',\n",
       " 'binary_remote_addr',\n",
       " 'alter',\n",
       " 'cookie_',\n",
       " 'orelse',\n",
       " 'scrollbar',\n",
       " 'scroll',\n",
       " '@charset',\n",
       " 'orphans',\n",
       " 'server_protocol',\n",
       " '_ENCODING_',\n",
       " 'empty',\n",
       " 'ssl_session_reused',\n",
       " 'finally',\n",
       " 'timing',\n",
       " 'that',\n",
       " 'row',\n",
       " 'strike',\n",
       " 'ubyte',\n",
       " 'args',\n",
       " 'optional',\n",
       " 'DEFAULT',\n",
       " 'async',\n",
       " 'nonmutating',\n",
       " 'atomic_noexcept',\n",
       " 'vararg',\n",
       " 'prefix',\n",
       " 'cshort',\n",
       " 'pragma',\n",
       " 'origin',\n",
       " 'rule',\n",
       " 'class',\n",
       " 'DOCTYPE',\n",
       " 'samp',\n",
       " 'ssl_alpn_protocol',\n",
       " 'import',\n",
       " 'form',\n",
       " 'INTO',\n",
       " 'rotate',\n",
       " 'noexcept',\n",
       " 'arguments',\n",
       " '__single_inheritancee',\n",
       " 'deferred',\n",
       " '__int32',\n",
       " 'lua_isboolean',\n",
       " 'Type',\n",
       " 'throws',\n",
       " 'DISTINCT',\n",
       " '#include',\n",
       " 'asm',\n",
       " 'DELETE',\n",
       " 'func',\n",
       " 'cell',\n",
       " 'sync',\n",
       " 'input',\n",
       " 'foreach',\n",
       " 'interface struct',\n",
       " 'cite',\n",
       " 'field',\n",
       " 'cbyte',\n",
       " '__inline',\n",
       " 'request_body_file',\n",
       " 'fill',\n",
       " 'endswitch',\n",
       " 'flex',\n",
       " 'space',\n",
       " 'lua_getglobal',\n",
       " 'slice',\n",
       " 'sub',\n",
       " 'transition',\n",
       " 'uid_got',\n",
       " 'date_gmt',\n",
       " 'unsafe_unretained',\n",
       " 'not',\n",
       " 'all',\n",
       " 'upstream_connect_time',\n",
       " 'body_bytes_sent',\n",
       " 'tuple',\n",
       " 'center',\n",
       " 'endfor',\n",
       " 'INDEX',\n",
       " 'nav',\n",
       " 'unique',\n",
       " '__except',\n",
       " 'using',\n",
       " 'top',\n",
       " 'repeat',\n",
       " '__FUNCTION__',\n",
       " 'delete',\n",
       " 'else',\n",
       " 'constexpr',\n",
       " 'is',\n",
       " 'east',\n",
       " 'bytes_received',\n",
       " 'only',\n",
       " 'requires',\n",
       " 'setparam',\n",
       " 'chan',\n",
       " 'explicit',\n",
       " 'string',\n",
       " 'stretch',\n",
       " 'register',\n",
       " 'unicode',\n",
       " 'bytes',\n",
       " 'none',\n",
       " 'remote_user',\n",
       " 'ssl_ciphers',\n",
       " 'COPY',\n",
       " 'ssl_client_v_remain',\n",
       " 'start',\n",
       " 'composite',\n",
       " 'p',\n",
       " 'lua_isnumber',\n",
       " 'date_local',\n",
       " 'geoip_city_country_code',\n",
       " 'request_uri',\n",
       " 'alignas',\n",
       " 'request_filename',\n",
       " 'svg',\n",
       " 'invalid_referer',\n",
       " 'h4',\n",
       " 'request',\n",
       " 'LIMIT',\n",
       " 'BACKUP',\n",
       " 'INNER',\n",
       " 'nonatomic',\n",
       " '__gc',\n",
       " 'precedencegroup',\n",
       " 'quotes',\n",
       " 'inout',\n",
       " 'continue',\n",
       " '__pin',\n",
       " 'event',\n",
       " 'acronym',\n",
       " 'lambda',\n",
       " '__finally',\n",
       " 'geoip_country_code',\n",
       " 'ascending',\n",
       " 'unsized',\n",
       " 'this',\n",
       " 'clng',\n",
       " 'big',\n",
       " 'lua_equal',\n",
       " 'some',\n",
       " 'HAVING',\n",
       " 'single',\n",
       " 'style',\n",
       " 'go',\n",
       " 'limit',\n",
       " 'wrap',\n",
       " 'cursor',\n",
       " 'a',\n",
       " 'indirect',\n",
       " 'wait',\n",
       " 'title',\n",
       " 'assembly',\n",
       " 'anchor',\n",
       " 'null',\n",
       " 'lua_isnoneornil',\n",
       " 'BY',\n",
       " 'lua_gettable',\n",
       " 'ssl_client_s_dn',\n",
       " 'mqtt_preread_username',\n",
       " 'abbr',\n",
       " 'BEGIN',\n",
       " 'display',\n",
       " 'if',\n",
       " 'managed',\n",
       " 'rownum',\n",
       " 'ensure',\n",
       " 'data',\n",
       " 'rendering',\n",
       " 'BETWEEN',\n",
       " 'noscript',\n",
       " 'raise',\n",
       " '__hook',\n",
       " 'state',\n",
       " '__int8',\n",
       " 'strong',\n",
       " 'isset',\n",
       " 'equals',\n",
       " 'upstream_cookie_',\n",
       " 'IN',\n",
       " 'signed',\n",
       " 'request_length',\n",
       " 'msec',\n",
       " 'nint',\n",
       " 'SET',\n",
       " 'lua_insert',\n",
       " 'vertical',\n",
       " 'fit',\n",
       " 'upstream_cache_status',\n",
       " 'dl',\n",
       " 'em',\n",
       " 'tailrec',\n",
       " 'UNIQUE',\n",
       " 'by',\n",
       " '__fastcall',\n",
       " 'typeid',\n",
       " 'word',\n",
       " 'char8_t',\n",
       " 'UPDATE',\n",
       " 'key',\n",
       " 'td',\n",
       " 'primary',\n",
       " 'eval',\n",
       " 'co_await',\n",
       " 'z',\n",
       " 'number',\n",
       " 'y',\n",
       " 'mix',\n",
       " 'endif',\n",
       " 'bdo',\n",
       " 'namespace',\n",
       " 'andalso',\n",
       " 'infix',\n",
       " '_LINE_',\n",
       " 'direction',\n",
       " 'lateinit',\n",
       " 'upright',\n",
       " 'self',\n",
       " 'ushort',\n",
       " 'typeof',\n",
       " 'synchronized',\n",
       " 'link',\n",
       " 'CGFloat',\n",
       " 'yield',\n",
       " 'rows',\n",
       " 'img',\n",
       " 'proxy_protocol_tlv_aws_vpce_id',\n",
       " 'status',\n",
       " 'lua_isnone',\n",
       " 'ssl_preread_protocol',\n",
       " 'checked',\n",
       " 'exit',\n",
       " 'collapse',\n",
       " 'increment',\n",
       " 'hyphens',\n",
       " 'mask',\n",
       " 'int8',\n",
       " 'unmanaged',\n",
       " 'order',\n",
       " 'upstream_trailer_',\n",
       " 'pre',\n",
       " 'lua_getallocf',\n",
       " 'clear',\n",
       " 'gap',\n",
       " 'receiver',\n",
       " 'remote_addr',\n",
       " 'final',\n",
       " 'xor',\n",
       " 'STOPSIGNAL',\n",
       " 'lua_call',\n",
       " 'lua_isfunction',\n",
       " 'upstream_header_time',\n",
       " '__METHOD__',\n",
       " 'tt',\n",
       " 'uint16',\n",
       " 'connection_time',\n",
       " 'let',\n",
       " 'ssl_preread_server_name',\n",
       " 'new',\n",
       " 'padding',\n",
       " 'dt',\n",
       " 'x',\n",
       " 'lua_newtable',\n",
       " 'use',\n",
       " 'head',\n",
       " 'main',\n",
       " 'content_type',\n",
       " 'decltype',\n",
       " 'dynamic',\n",
       " 'mixin',\n",
       " 'ulongint',\n",
       " 'text',\n",
       " '__super',\n",
       " 'partial',\n",
       " 'before',\n",
       " 'track',\n",
       " 'mod',\n",
       " 'geoip_latitude',\n",
       " 'set',\n",
       " 'jwt_payload',\n",
       " 'otel_span_id',\n",
       " 'range',\n",
       " 'dynamic_cast',\n",
       " 'object',\n",
       " 'init',\n",
       " 'figure',\n",
       " 'global',\n",
       " 'try',\n",
       " 'items',\n",
       " 'address',\n",
       " 'constraint',\n",
       " '__FILE__',\n",
       " 'shl',\n",
       " 'h6',\n",
       " '__assume',\n",
       " 'interface class',\n",
       " 'insteadof',\n",
       " 'record',\n",
       " 'fastcgi_path_info',\n",
       " 'proxy_protocol_tlv_azure_pel_id',\n",
       " 'into',\n",
       " '__ptr64e',\n",
       " 'constant',\n",
       " 'as_friend',\n",
       " 'button',\n",
       " '__if_not_exists',\n",
       " 'PRIMARY',\n",
       " 'label',\n",
       " 'subscript',\n",
       " 'shr',\n",
       " 'ancient_browser',\n",
       " 'lua_createtable',\n",
       " 'default',\n",
       " 'remote_port',\n",
       " 'static_assert',\n",
       " 'VIEW',\n",
       " 'width',\n",
       " 'opacity',\n",
       " 'bitor',\n",
       " 'char',\n",
       " 'geoip_region',\n",
       " 'typename',\n",
       " 'delay',\n",
       " 'FOREIGN',\n",
       " 'super',\n",
       " 'crossinline',\n",
       " 'ssl_curve',\n",
       " 'inset',\n",
       " 'tcpinfo_rttvar',\n",
       " 'datalist',\n",
       " 'values',\n",
       " 'NOT',\n",
       " 'uid_reset',\n",
       " '__m128d',\n",
       " 'request_time',\n",
       " 'TABLE',\n",
       " 'weak',\n",
       " 'http_',\n",
       " 'upstream_session_time',\n",
       " 'output',\n",
       " 'to',\n",
       " 'th',\n",
       " 'vector',\n",
       " 'NSObject',\n",
       " 'inside',\n",
       " 'list',\n",
       " 'get',\n",
       " 'limit_conn_status',\n",
       " 'clip',\n",
       " 'geoip_city_country_name',\n",
       " 'lua_isstring',\n",
       " 'lua_isthread',\n",
       " 'document_uri',\n",
       " 'expect',\n",
       " 'hide',\n",
       " '__interface',\n",
       " 'geoip_region_name',\n",
       " 'COLUMN',\n",
       " 'ref class',\n",
       " 'punctuation',\n",
       " 'outset',\n",
       " 'mark',\n",
       " 'mutating',\n",
       " 'page',\n",
       " 'factory',\n",
       " 'print',\n",
       " 'not_eq',\n",
       " 'loop',\n",
       " 'TOP',\n",
       " 'thread_local',\n",
       " 'companion',\n",
       " 'name',\n",
       " 'lua_islightuserdata',\n",
       " 'inner',\n",
       " 'animation',\n",
       " 'literal',\n",
       " 'resize',\n",
       " 'workflow',\n",
       " 'lua_concat',\n",
       " 'lua_newstate',\n",
       " 'upstream_bytes_sent',\n",
       " '__raise',\n",
       " 'inlinescript',\n",
       " 'lua_getfield',\n",
       " 'feature',\n",
       " '__box',\n",
       " 'clngint',\n",
       " 'combine',\n",
       " 'guard',\n",
       " '__vectorcall',\n",
       " 'int32',\n",
       " 'widows',\n",
       " 'aspect',\n",
       " 'between',\n",
       " 'optgroup',\n",
       " 'version',\n",
       " 'ENTRYPOINT',\n",
       " 'meter',\n",
       " 'short',\n",
       " 'meta',\n",
       " 'tcpinfo_rcv_space',\n",
       " 'columns',\n",
       " 'retain',\n",
       " 'alternates',\n",
       " 'RUN',\n",
       " 'volatile',\n",
       " 'int64',\n",
       " '@font',\n",
       " 'lua_Integer',\n",
       " 'upstream_response_length',\n",
       " 'family',\n",
       " 'shrink',\n",
       " 'ROWNUM',\n",
       " 'safecast',\n",
       " 'grid',\n",
       " 'nullptr',\n",
       " 'asc',\n",
       " 'unchecked',\n",
       " 'font',\n",
       " 'compl',\n",
       " 'payable',\n",
       " 'progress',\n",
       " 'mapping',\n",
       " 'NULL',\n",
       " 'undef',\n",
       " 'impure',\n",
       " 'or_eq',\n",
       " 'tr',\n",
       " 'textarea',\n",
       " 'module',\n",
       " 'sizing',\n",
       " 'column',\n",
       " 'value',\n",
       " 'DATABASE',\n",
       " 'co_yield',\n",
       " 'enum struct',\n",
       " 'DESC',\n",
       " 'min',\n",
       " 'debugger',\n",
       " 'applet',\n",
       " 'coproc',\n",
       " 'index',\n",
       " 'NSInteger',\n",
       " 'descending',\n",
       " 'sup',\n",
       " 'xor_eq',\n",
       " 'ADD',\n",
       " 'uint',\n",
       " 'border',\n",
       " '__based',\n",
       " 'is_args',\n",
       " 'friend',\n",
       " '@import',\n",
       " 'synthesis',\n",
       " 'jwt_header_',\n",
       " 'CREATE',\n",
       " 'precedence',\n",
       " 'ol',\n",
       " 'break',\n",
       " 'proxy_protocol_tlv_gcp_conn_id',\n",
       " 'reinterpret_cast',\n",
       " 'base',\n",
       " 'fallback',\n",
       " 'lua_gc',\n",
       " 'impl',\n",
       " 'pid',\n",
       " 'realpath_root',\n",
       " 'server_addr',\n",
       " 'enum',\n",
       " '__wchar_t',\n",
       " 'visibility',\n",
       " 'covariant',\n",
       " 'fieldset',\n",
       " 'modifier',\n",
       " '_FILE_',\n",
       " 'enddeclare',\n",
       " 'local',\n",
       " 'lua_CFunction',\n",
       " 'where',\n",
       " 'boolean',\n",
       " 'area',\n",
       " 'kbd',\n",
       " 'ssl_client_raw_cert',\n",
       " 'warning',\n",
       " 'align',\n",
       " 'geoip_dma_code',\n",
       " 'nameof',\n",
       " 'end',\n",
       " 'server_port',\n",
       " 'END',\n",
       " 'file',\n",
       " 'color',\n",
       " 'macro_rules',\n",
       " 'msie',\n",
       " '__restrict',\n",
       " 'static',\n",
       " 'proxy_add_x_forwarded_for',\n",
       " 'public',\n",
       " 'extends',\n",
       " 'endforeach',\n",
       " 'priv',\n",
       " 'rethrow',\n",
       " 'ulong',\n",
       " 'writing',\n",
       " 'h3',\n",
       " 'sent_http_',\n",
       " 'imageLiteral',\n",
       " 'echo',\n",
       " 'otel_parent_id',\n",
       " 'shortint',\n",
       " 'ssl_client_cert',\n",
       " 'menu',\n",
       " 'request_id',\n",
       " '__uuidof',\n",
       " 'byte',\n",
       " 'RIGHT',\n",
       " 'ENV',\n",
       " 'VOLUME',\n",
       " 'line',\n",
       " 'until',\n",
       " 'justify',\n",
       " 'sourceLocation',\n",
       " 'UNION',\n",
       " 'hypenate',\n",
       " 'sealed',\n",
       " 'upstream_first_byte_time',\n",
       " 'inline',\n",
       " 'elif',\n",
       " 'time_local',\n",
       " 'DROP',\n",
       " 'condition',\n",
       " 'backface',\n",
       " 'csng',\n",
       " 'select',\n",
       " 'upstream_queue_time',\n",
       " 'layout',\n",
       " 'check',\n",
       " 'map',\n",
       " 'ONBUILD',\n",
       " 'package',\n",
       " 'sequence',\n",
       " 'associativity',\n",
       " 'ins',\n",
       " 'details',\n",
       " 'q',\n",
       " 'late',\n",
       " 'colorLiteral',\n",
       " 'like',\n",
       " 'cubyte',\n",
       " 'areas',\n",
       " 'strictfp',\n",
       " 'document_root',\n",
       " 'stackalloc',\n",
       " 'option',\n",
       " 'procedure',\n",
       " 'parallel',\n",
       " 'willSet',\n",
       " '__try_cast',\n",
       " '__NAMESPACE__',\n",
       " 'dim',\n",
       " 'IS',\n",
       " 'enum class',\n",
       " 'having',\n",
       " 'die',\n",
       " 'elseif',\n",
       " 'selector',\n",
       " 'export',\n",
       " 'drop',\n",
       " 'side',\n",
       " '__w64',\n",
       " 'implementation',\n",
       " 'next',\n",
       " 'slice_range',\n",
       " 'h2',\n",
       " 'margin',\n",
       " 'play',\n",
       " 'translate',\n",
       " 'lua_isuserdata',\n",
       " 'PROCEDURE',\n",
       " 'None',\n",
       " 'duration',\n",
       " 'picture',\n",
       " '__m128i',\n",
       " 'orientation',\n",
       " 'lua_getfenv',\n",
       " 'noinline',\n",
       " 'lua_isnil',\n",
       " 'lua_lessthan',\n",
       " 'ssl_client_verify',\n",
       " 'suspend',\n",
       " 'fallthrough',\n",
       " '__int64',\n",
       " 'geoip_country_name',\n",
       " 'initonly',\n",
       " 'typedef',\n",
       " 'create',\n",
       " 'AS',\n",
       " 'numeric',\n",
       " 'property',\n",
       " 'elsif',\n",
       " 'ssl_early_data',\n",
       " 'group',\n",
       " '__halt_compiler',\n",
       " 'language',\n",
       " 'u',\n",
       " 'then',\n",
       " 'qword',\n",
       " 'weight',\n",
       " 'canvas',\n",
       " 'ref struct',\n",
       " 'full',\n",
       " 'html',\n",
       " 'when',\n",
       " 'nuint',\n",
       " 'override',\n",
       " 'backup',\n",
       " 'limit_req_status',\n",
       " 'offset',\n",
       " 'host',\n",
       " 'reified',\n",
       " 'request_body',\n",
       " 'filter',\n",
       " '__unhook',\n",
       " 'exists',\n",
       " 'thead',\n",
       " 'required',\n",
       " 'constructor',\n",
       " 'content_length',\n",
       " 'lua_istable',\n",
       " 'insert',\n",
       " 'false',\n",
       " 'umask',\n",
       " 'outline',\n",
       " 'hostname',\n",
       " 'alignof',\n",
       " 'br',\n",
       " 'include',\n",
       " 'available',\n",
       " 'mutable',\n",
       " 'culngint',\n",
       " 'ssl_session_id',\n",
       " 'reflect',\n",
       " 'ORDER',\n",
       " 'caps',\n",
       " 'variant',\n",
       " 'wchar_t',\n",
       " 'position',\n",
       " '__nogc',\n",
       " '#pragma',\n",
       " 'USER',\n",
       " 'footer',\n",
       " 'face',\n",
       " 'SHELL',\n",
       " 'limit_rate',\n",
       " 'for',\n",
       " 'height',\n",
       " 'stop',\n",
       " 'dsohandle',\n",
       " 'realip_remote_addr',\n",
       " 'join',\n",
       " 'proxy_protocol_port',\n",
       " 'true',\n",
       " 'WHERE',\n",
       " 'span',\n",
       " 'connection',\n",
       " '__event',\n",
       " 'truncate',\n",
       " 'do',\n",
       " 'geoip_city_country_code3',\n",
       " '__leave',\n",
       " 'remove',\n",
       " 'CONSTRAINT',\n",
       " 'ANY',\n",
       " 'https',\n",
       " 'lua_dump',\n",
       " '__stdcall',\n",
       " 'HEALTHCHECK',\n",
       " 'request_method',\n",
       " 'ssl_client_i_dn',\n",
       " 'params',\n",
       " 'query_string',\n",
       " 'VALUES',\n",
       " 'char16_t',\n",
       " 'scoped',\n",
       " 'any',\n",
       " 'protected',\n",
       " 'dd',\n",
       " 'array',\n",
       " 'request_completion',\n",
       " 'realip_remote_port',\n",
       " '__value',\n",
       " 'wend',\n",
       " 'instanceof',\n",
       " 'decimal',\n",
       " 'AND',\n",
       " 'abstract',\n",
       " 'audio',\n",
       " 'Function',\n",
       " 'ssl_preread_alpn_protocols',\n",
       " 'in',\n",
       " 'protocol',\n",
       " 'atomic_cancel',\n",
       " 'GROUP',\n",
       " 'records',\n",
       " '__identifier',\n",
       " 'extension',\n",
       " 'goto',\n",
       " 'grow',\n",
       " 'JOIN',\n",
       " 'shift',\n",
       " 'http3',\n",
       " 'OR',\n",
       " 'right',\n",
       " 'h5',\n",
       " 'geoip_area_code',\n",
       " '__ptr32',\n",
       " 'OUTER',\n",
       " 'proxy_protocol_tlv_',\n",
       " 'scale',\n",
       " 'consteval',\n",
       " 'rethrows',\n",
       " 'connections_active',\n",
       " '__virtual_inheritance',\n",
       " 'blockquote',\n",
       " 'orderby',\n",
       " 'http2',\n",
       " 'readonly',\n",
       " 'script',\n",
       " '_Packed',\n",
       " 'add',\n",
       " 'box',\n",
       " 's',\n",
       " 'time',\n",
       " 'place',\n",
       " 'defer',\n",
       " 'ssl_client_fingerprint',\n",
       " 'image',\n",
       " 'del',\n",
       " 'long',\n",
       " 'gcnew',\n",
       " 'longint',\n",
       " 'void',\n",
       " 'pub',\n",
       " 'asian',\n",
       " 'culng',\n",
       " 'adjust',\n",
       " 'extern',\n",
       " '__uptr',\n",
       " 'associatedtype',\n",
       " 'LABEL',\n",
       " 'foreign',\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "keywords_root = Path(\"../dataset_v1/data/raw/keywords2\")\n",
    "keywords = []\n",
    "\n",
    "for tglang_keywords in keywords_root.iterdir():\n",
    "    tglang = tglang_keywords.name.split(\".\")[0]\n",
    "    with open(tglang_keywords) as f:\n",
    "        keywords += list(map(lambda x: x.strip(), f.readlines()))\n",
    "\n",
    "keywords = list(set(keywords))\n",
    "keywords_set = set(keywords)\n",
    "\n",
    "keywords_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd7820b-d75a-43f9-9615-2612aa1108ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TGLANG_LANGUAGE_OTHER',\n",
       " 'TGLANG_LANGUAGE_C',\n",
       " 'TGLANG_LANGUAGE_CPLUSPLUS',\n",
       " 'TGLANG_LANGUAGE_CSHARP',\n",
       " 'TGLANG_LANGUAGE_CSS',\n",
       " 'TGLANG_LANGUAGE_DART',\n",
       " 'TGLANG_LANGUAGE_DOCKER',\n",
       " 'TGLANG_LANGUAGE_FUNC',\n",
       " 'TGLANG_LANGUAGE_GO',\n",
       " 'TGLANG_LANGUAGE_HTML',\n",
       " 'TGLANG_LANGUAGE_JAVA',\n",
       " 'TGLANG_LANGUAGE_JAVASCRIPT',\n",
       " 'TGLANG_LANGUAGE_JSON',\n",
       " 'TGLANG_LANGUAGE_KOTLIN',\n",
       " 'TGLANG_LANGUAGE_LUA',\n",
       " 'TGLANG_LANGUAGE_NGINX',\n",
       " 'TGLANG_LANGUAGE_OBJECTIVE_C',\n",
       " 'TGLANG_LANGUAGE_PHP',\n",
       " 'TGLANG_LANGUAGE_POWERSHELL',\n",
       " 'TGLANG_LANGUAGE_PYTHON',\n",
       " 'TGLANG_LANGUAGE_RUBY',\n",
       " 'TGLANG_LANGUAGE_RUST',\n",
       " 'TGLANG_LANGUAGE_SHELL',\n",
       " 'TGLANG_LANGUAGE_SOLIDITY',\n",
       " 'TGLANG_LANGUAGE_SQL',\n",
       " 'TGLANG_LANGUAGE_SWIFT',\n",
       " 'TGLANG_LANGUAGE_TL',\n",
       " 'TGLANG_LANGUAGE_TYPESCRIPT',\n",
       " 'TGLANG_LANGUAGE_XML']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_maps = pd.read_parquet(eval_path)\n",
    "\n",
    "target_2_lang = {}\n",
    "for idx, row in df_for_maps[[\"target\", \"tglang\"]].drop_duplicates().iterrows():\n",
    "    target_2_lang[row[\"target\"]] = row[\"tglang\"]\n",
    "\n",
    "d = []\n",
    "for target, tglang in target_2_lang.items():\n",
    "    d.append((target, tglang))\n",
    "\n",
    "tglang_names = list(map(lambda x: x[1], sorted(d)))\n",
    "tglang_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7dae19-8446-483a-9409-6cdf4d75b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    single_token_ids  = set([9,10,32,34,39,40,41,44,59,91,93,96,123,125])\n",
    "    word_ids          = set(list(range(65, 91)) + list(range(97, 123)) + [95])\n",
    "    number_ids        = set(list(range(48, 58)))\n",
    "    symbol_ids        = set([33,35,36,37,38,42,43,45,46,47,58,60,61,62,63,64,92,94,95,124,126])\n",
    "    \n",
    "    tokens = []\n",
    "    cache = []\n",
    "    token_type = 0\n",
    "    \n",
    "    for idx, c in enumerate(s):\n",
    "        id = ord(c)\n",
    "    \n",
    "        if id in single_token_ids:\n",
    "\n",
    "            if len(cache) > 0 and (token_type == 1 or token_type == 2 or token_type == 3):\n",
    "                tokens.append(\"\".join(cache))\n",
    "            cache = []\n",
    "            tokens.append(c)\n",
    "            token_type = 0\n",
    "\n",
    "        elif id in word_ids or (token_type == 1 and id in number_ids):\n",
    "\n",
    "            if token_type == 0:\n",
    "                cache = [c]\n",
    "            elif token_type == 1:\n",
    "                cache.append(c)\n",
    "            elif token_type == 2:\n",
    "                tokens.append(\"\".join(cache))\n",
    "                cache = [c]\n",
    "            elif token_type == 3:\n",
    "                tokens.append(\"\".join(cache))\n",
    "                cache = [c]\n",
    "            token_type = 1\n",
    "\n",
    "        elif id in symbol_ids:\n",
    "\n",
    "            if token_type == 0:\n",
    "                cache = [c]\n",
    "            elif token_type == 1:\n",
    "                tokens.append(\"\".join(cache))\n",
    "                cache = [c]\n",
    "            elif token_type == 2:\n",
    "                cache.append(c)\n",
    "            elif token_type == 3:\n",
    "                tokens.append(\"\".join(cache))\n",
    "                cache = [c]\n",
    "            token_type = 2\n",
    "\n",
    "        elif id in number_ids:\n",
    "\n",
    "            if token_type == 0:\n",
    "                cache = [c]\n",
    "            elif token_type == 1:\n",
    "                tokens.append(\"\".join(cache))\n",
    "                cache = [c]\n",
    "            elif token_type == 2:\n",
    "                tokens.append(\"\".join(cache))\n",
    "                cache = [c]\n",
    "            elif token_type == 3:\n",
    "                cache.append(c)\n",
    "            token_type = 3\n",
    "\n",
    "        else:\n",
    "            if len(cache) > 0 and (token_type == 1 or token_type == 2 or token_type == 3):\n",
    "                tokens.append(\"\".join(cache))\n",
    "            cache = []\n",
    "            token_type = 0\n",
    "\n",
    "        # print(c, id, cache)\n",
    "\n",
    "    if len(cache) > 0 and (token_type == 1 or token_type == 2 or token_type == 3):\n",
    "        tokens.append(\"\".join(cache))\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def filter_tokens(tokens):\n",
    "    return list(filter(lambda x: x != \" \" and x != \"\", tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c2b1121-db53-455a-a825-fab5df707283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0009090790748596192, 4288)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "code = \"\"\"\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sys import argv\n",
    "from time import sleep\n",
    "from typing import List\n",
    " \n",
    " \n",
    "def walk_directory(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[0][-4:] != \"CODE\":\n",
    "                continue\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                content = f.read()\n",
    "            yield (content, file_path)\n",
    " \n",
    " \n",
    "openai.api_key = \"sk-2UNhL8AnOUZ1JogW8246Df2e279044348d53680e68Ea57A0\"\n",
    "openai.api_base = \"https://neuroapi.host/v1\"\n",
    "LANGS = ['CPLUSPLUS', 'JAVA', 'CSS', 'OBJECTIVE_C', 'GO', 'NGINX', 'LUA',\n",
    "         'KOTLIN', 'DOCKER', 'JAVASCRIPT', 'PYTHON', 'SHELL', 'SOLIDITY',\n",
    "         'HTML', 'RUST', 'PHP', 'DART', 'C', 'TYPESCRIPT', 'SWIFT', 'SQL',\n",
    "         'TL', 'POWERSHELL', 'JSON', 'FUNC', 'XML', 'RUBY', 'CSHARP']\n",
    "request_template = \"\\n\".join([\n",
    "    f\"You must answer with ONLY ONE 'word', an element from this list: {LANGS}\",\n",
    "    \"Under no circumstances should you write anything other than one word from the list above.\",\n",
    "    \"Your task is to guess in which programming language from those presented this piece of code is written:\",\n",
    "    \"```\\n{}\\n```\",\n",
    "    \"Even if you recognize a language and it is not in the list presented, still find the most suitable one, for example, instead of BASH write SHELL, etc. If nothing at all fits, indicate a random language, but do not write anything that is not on the list. You must follow the spelling of the words on the list exactly.\"\n",
    "    \"If your answer is even one character different from the correct element from the list, I will suffer terribly for many days.\",\n",
    " \n",
    "    # \"If enone of the languages in the list is suitable, write `OTHER`. UNDER NO CIRCUMSTANCES WRITE ANYTHING BUT ONE WORD. IT MUST BE AN ELEMENT FROM THE LIST UP TO EACH CHARACTER.\"\n",
    "])\n",
    " \n",
    " \n",
    "def get_content(request: str) -> str:\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature = 0.2,\n",
    "        messages=[{\"role\": \"user\", \"content\": request}],\n",
    "        stream=False,\n",
    "        timeout=5,\n",
    "    )\n",
    " \n",
    "    if isinstance(chat_completion, dict):\n",
    "        # not stream\n",
    "        content = chat_completion.choices[0].message.content\n",
    "        return content\n",
    "    else:\n",
    "        res = []\n",
    "        for token in chat_completion:\n",
    "            content = token[\"choices\"][0][\"delta\"].get(\"content\")\n",
    "            if content != None:\n",
    "                res.append(content)\n",
    "        return \"\".join(res)\n",
    " \n",
    " \n",
    "def make_files(samples: list, start: int, pb: tqdm = None):\n",
    "    results = []\n",
    "    for code, file_path in samples:\n",
    "        try:\n",
    "            label = get_content(request_template.format(code))\n",
    "            print(label)\n",
    "        except Exception as e:\n",
    "            sleep(1)\n",
    "            print(e)\n",
    "            # label = get_content(request_template.format(code))\n",
    "            label = \"OTHER\"\n",
    "            continue\n",
    "        if len(label) > 12:\n",
    "            label = \"OTHER\"\n",
    "        results.append([file_path, label])\n",
    "        pb.update()\n",
    "    return pd.DataFrame(results, columns=[\"path\", \"label\"])\n",
    " \n",
    "WORK_DIR = \"/home/kama/pythonProjects/telegram-ML-Competition-2023/datasets/test/\"\n",
    "def read_file(path):\n",
    "    with open(WORK_DIR + path, \"r\") as f:\n",
    "        return f.read(), path\n",
    " \n",
    "def get_text(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[~df[\"label\"].isin(set(LANGS))]\n",
    "    return [\n",
    "        list(read_file(p)) for p in df[\"path\"] \n",
    "    ]\n",
    " \n",
    "def main():\n",
    "    start_num = int(argv[1]) if len(argv) > 1 else 0\n",
    "    # dir_1 = \"/home/kama/pythonProjects/telegram-ML-Competition-2023/datasets/test/\"\n",
    "    # save_dir = \"gpt_cls_part_2\"\n",
    "    # samples = get_text(\"merged_1_prefinal.csv\")\n",
    "    df = pd.read_csv(\"merged_1_prefinal_2.csv\")\n",
    "    # df = df\n",
    "    samples = [\n",
    "        list(read_file(p)) for p in df[\"path\"][df[\"label\"].isin({\"OTHER\", \"ERROR\"})]\n",
    "    ][::-1]\n",
    "    print(len(samples))\n",
    "    d = 1\n",
    " \n",
    "    pb = tqdm(total=len(samples))\n",
    "    for k in range(start_num, len(samples), d):\n",
    "        df_2 = make_files(samples[k:k+d], k, pb)\n",
    "        m = pd.merge(df, df_2, on='path', how='left')\n",
    "        m['label'] = m['label_y'].fillna(m['label_x']).astype(str)\n",
    "        m = m[['path', 'label']]\n",
    "        m.to_csv(f\"merged_1_prefinal_2.csv\", index=False)\n",
    "        df = m\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "a = []\n",
    "\n",
    "for i in range(1000):\n",
    "    start = time()\n",
    "    code_tokens = my_tokenizer(code)\n",
    "    a.append(time() - start)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.mean(a), len(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60778210-33f6-4dcf-ae85-d312a52fb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_ids          = set(list(range(65, 91)) + list(range(97, 123)) + [95])\n",
    "\n",
    "def enrich_with_tranformed_code_column(dataset):\n",
    "    dataset[\"code_enrichment\"] = dataset[\"code\"].apply(\n",
    "        lambda x: \" \".join(filter(lambda x: (x[0] not in word_ids) or (x in keywords_set), my_tokenizer(x)))\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f8cbf8-f50e-4438-9806-a3b5c1a2ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(train_path, 4000)\n",
    "eval  = load_dataset(eval_path, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a1761af-f0a9-4e8b-af8a-a9b5042e8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# train = train.sample(frac=1).reset_index(drop=True)\n",
    "# split_index = math.floor(train.shape[0] * 0.8)\n",
    "# print(\"split_index\", split_index)\n",
    "\n",
    "# train_ = train.iloc[:split_index]\n",
    "# move_to_eval_ = train.iloc[split_index:]\n",
    "\n",
    "# train = train_\n",
    "# eval  = pd.concat([move_to_eval_, eval]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c31aadd-346d-4e40-87fe-bd0d1719feac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((109757, 3), (11246, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57ceb5e9-3605-4a89-b389-05d4eae1dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = enrich_with_tranformed_code_column(train)\n",
    "eval = enrich_with_tranformed_code_column(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3298732a-c8f8-4928-95f4-2732cf36fd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def char2num(c):\n",
    "    n = ord(c)\n",
    "    if n == 10:\n",
    "        return 0\n",
    "    elif  n <= 31 or n >= 127:\n",
    "        return 96\n",
    "    else:\n",
    "        return n - 31\n",
    "\n",
    "\n",
    "def get_embedding(s: str):\n",
    "    if len(s) == 0:\n",
    "        return np.zeros((96, ))\n",
    "    res = np.array(np.bincount([char2num(c) for c in s], minlength=97), dtype=float) / len(s)\n",
    "    return res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5b0de-b5ca-4c92-a5e0-ab494887f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_baseline_score(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.preprocessing import FunctionTransformer\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    manual_best_params = {\n",
    "        'criterion': 'gini',\n",
    "        'max_features': 'sqrt',\n",
    "        'min_samples_split': 2,\n",
    "        'min_samples_leaf': 1,\n",
    "        'n_estimators': 300,\n",
    "        'max_depth': 80\n",
    "    }\n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=4, **manual_best_params)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(f'Accuracy: {clf.score(X_test, y_test)}')\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"f1_score\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"precision_score\", precision_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(classification_report(y_test, y_pred, target_names=tglang_names))\n",
    "    print(\"balanced_accuracy_score\", balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618a7a02-31e2-4185-98f1-c3ec85e44f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "def word2token(word: str):\n",
    "    if re.search(r'[^a-zA-Z0-9_]', word):\n",
    "        return None\n",
    "    return ''.join([\n",
    "        'A' if word[0].isupper() else ('a' if word[0].islower() else '_'),  # startswith 'A', 'a' or '_'\n",
    "        'a' if any(map(str.islower, word[1:])) else '',\n",
    "        'A' if any(map(str.isupper, word[1:])) else '',\n",
    "        '_' if '_' in word else '',\n",
    "        '2' if len(word) > 10 else ('0' if len(word) == 1 else \"1\")\n",
    "    ])\n",
    "\n",
    "def word2token_new(word: str):\n",
    "    if word.isdigit():\n",
    "        return '0'\n",
    "    if (word in keywords_set) or re.search(r'[^a-zA-Z0-9_]', word):\n",
    "        return word\n",
    "    return ''.join([\n",
    "        'A' if word[0].isupper() else ('a' if word[0].islower() else '_'),  # startswith 'A', 'a' or '_'\n",
    "        'a' if any(map(str.islower, word[1:])) else '',\n",
    "        'A' if any(map(str.isupper, word[1:])) else '',\n",
    "        '_' if '_' in word else '',\n",
    "        '2' if len(word) > 10 else ('0' if len(word) == 1 else \"1\")\n",
    "    ])\n",
    "\n",
    "def identity_tokenizer(text):\n",
    "    return text\n",
    "\n",
    "\n",
    "# alphnum[\"total\"] = alphnum[\"code\"].str.len()\n",
    "# alphnum[\"numbers\"] = alphnum[\"code\"].apply(lambda s: sum(c.isdigit() for c in s))\n",
    "# alphnum[\"letters\"] = alphnum[\"code\"].apply(lambda s: sum(c.isalpha() for c in s))\n",
    "# alphnum[\"spaces\"] = alphnum[\"code\"].apply(lambda s: sum(c.isspace() for c in s))\n",
    "# alphnum[\"other\"] = alphnum[\"code\"].apply(lambda s: sum(not(c.isspace() or c.isalpha() or c.isdigit()) for c in s))\n",
    "\n",
    "\n",
    "def feature_1(code_iterator):\n",
    "    return list(map(\n",
    "        lambda x: sum(c.isdigit() for c in x) / len(x),\n",
    "        code_iterator\n",
    "    ))\n",
    "\n",
    "def feature_2(code_iterator):\n",
    "    return list(map(\n",
    "        lambda x: sum(c.isalpha() for c in x) / len(x),\n",
    "        code_iterator\n",
    "    ))\n",
    "\n",
    "def feature_3(code_iterator):\n",
    "    return list(map(\n",
    "        lambda x: sum(c.isspace() for c in x) / len(x),\n",
    "        code_iterator\n",
    "    ))\n",
    "\n",
    "def feature_4(code_iterator):\n",
    "    return list(map(\n",
    "        lambda x: sum(not(c.isspace() or c.isalpha() or c.isdigit()) for c in x) / len(x),\n",
    "        code_iterator\n",
    "    ))\n",
    "\n",
    "def feature_5(code_iterator):\n",
    "    return list(map(\n",
    "        get_embedding,\n",
    "        code_iterator\n",
    "    ))\n",
    "\n",
    "def get_embeddings(train_code, train_target, test_code, test_target, tf_idf_params=None):\n",
    "    if tf_idf_params is None:\n",
    "        tf_idf_params = {\n",
    "            \"tokenizer\": identity_tokenizer,\n",
    "            \"max_features\": 1500,\n",
    "            \"lowercase\": False\n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "        Enrich train\n",
    "    \"\"\"\n",
    "    print(len(train_code))\n",
    "    train_tokens = map(my_tokenizer, train_code)\n",
    "    train_tokens = map(\n",
    "        lambda x: list(map(word2token_new, x)),\n",
    "        train_tokens\n",
    "    )\n",
    "    train_data = list(filter(\n",
    "        lambda x: len(x[0]) > 0,\n",
    "        zip(train_tokens, train_target, train_code)\n",
    "    ))\n",
    "    print(len(train_data))\n",
    "    train_tokens = list(map(lambda x: x[0], train_data))\n",
    "    train_target = list(map(lambda x: x[1], train_data))\n",
    "    train_code   = list(map(lambda x: x[2], train_data))\n",
    "\n",
    "    \"\"\"\n",
    "        Enrich test\n",
    "    \"\"\"\n",
    "    test_tokens = map(my_tokenizer, test_code)\n",
    "    test_tokens = map(\n",
    "        lambda x: list(map(word2token_new, x)),\n",
    "        test_tokens\n",
    "    )\n",
    "    test_data = list(filter(\n",
    "        lambda x: len(x[0]) > 0,\n",
    "        zip(test_tokens, test_target, test_code)\n",
    "    ))\n",
    "    test_tokens = list(map(lambda x: x[0], test_data))\n",
    "    test_target = list(map(lambda x: x[1], test_data))\n",
    "    test_code   = list(map(lambda x: x[2], test_data))\n",
    "\n",
    "    \"\"\"\n",
    "        Vectorize\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(**tf_idf_params)\n",
    "    vectorizer.fit(train_tokens)\n",
    "\n",
    "    train_embeddings = vectorizer.transform(train_tokens)\n",
    "    test_embeddings  = vectorizer.transform(test_tokens)\n",
    "\n",
    "    train_embeddings = train_embeddings.toarray()\n",
    "    test_embeddings  = test_embeddings.toarray()\n",
    "\n",
    "    for feature_ in []:\n",
    "        train_feature_ = np.array(feature_(train_code))\n",
    "\n",
    "        print(train_embeddings.shape)\n",
    "        print(train_feature_.shape)\n",
    "        \n",
    "        test_feature_  = np.array(feature_(test_code))\n",
    "        train_embeddings = np.c_[train_embeddings, train_feature_]\n",
    "        test_embeddings  = np.c_[test_embeddings,  test_feature_]\n",
    "\n",
    "    train_embeddings = sparse.csr_matrix(np.matrix(train_embeddings))\n",
    "    test_embeddings  = sparse.csr_matrix(np.matrix(test_embeddings))\n",
    "\n",
    "    return train_embeddings, train_target, test_embeddings, test_target, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeaa743f-c36d-44b6-ba2a-3c158aba0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109722\n",
      "109722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((109722, 1500), 109722, (11145, 1500), 11145)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = list(\n",
    "    map(\n",
    "        lambda x: (x[1], x[2]),\n",
    "        filter(\n",
    "            lambda x: len(x[0]) > 0,\n",
    "            map(\n",
    "                lambda y: (my_tokenizer(y[0]), y[0], y[1]),\n",
    "                zip(train[\"code\"], train[\"target\"])\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "train_code   = list(map(lambda x: x[0], train_data))\n",
    "train_target = list(map(lambda x: x[1], train_data))\n",
    "\n",
    "eval_data = list(\n",
    "    map(\n",
    "        lambda x: (x[1], x[2]),\n",
    "        filter(\n",
    "            lambda x: len(x[0]) > 0,\n",
    "            map(\n",
    "                lambda y: (my_tokenizer(y[0]), y[0], y[1]),\n",
    "                zip(eval[\"code\"], eval[\"target\"])\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "eval_code   = list(map(lambda x: x[0], eval_data))\n",
    "eval_target = list(map(lambda x: x[1], eval_data))\n",
    "\n",
    "X_test_svm = list(map(get_embedding, eval_code))\n",
    "\n",
    "X_train, y_train, X_test, y_test, tfidf = get_embeddings(train_code, train_target, eval_code, eval_target)\n",
    "X_train.shape, len(y_train), X_test.shape, len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f49b881-34a0-458a-a23c-8a0dd6270c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9227456258411844\n",
      "f1_score 0.42855124135530015\n",
      "precision_score 0.3757848596523379\n",
      "recall_score 0.5979489622573149\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "      TGLANG_LANGUAGE_OTHER       1.00      0.95      0.97     10186\n",
      "          TGLANG_LANGUAGE_C       0.51      0.70      0.59        30\n",
      "  TGLANG_LANGUAGE_CPLUSPLUS       0.73      0.73      0.73        37\n",
      "     TGLANG_LANGUAGE_CSHARP       0.62      0.84      0.71        19\n",
      "        TGLANG_LANGUAGE_CSS       0.44      0.73      0.55        15\n",
      "       TGLANG_LANGUAGE_DART       0.19      0.43      0.26         7\n",
      "     TGLANG_LANGUAGE_DOCKER       0.08      0.18      0.11        11\n",
      "       TGLANG_LANGUAGE_FUNC       0.00      0.00      0.00         1\n",
      "         TGLANG_LANGUAGE_GO       0.41      0.47      0.44        19\n",
      "       TGLANG_LANGUAGE_HTML       0.63      0.69      0.66        32\n",
      "       TGLANG_LANGUAGE_JAVA       0.64      0.22      0.33       113\n",
      " TGLANG_LANGUAGE_JAVASCRIPT       0.04      0.29      0.07         7\n",
      "       TGLANG_LANGUAGE_JSON       0.61      0.86      0.71        81\n",
      "     TGLANG_LANGUAGE_KOTLIN       0.30      0.85      0.44        13\n",
      "        TGLANG_LANGUAGE_LUA       0.34      0.68      0.45        25\n",
      "      TGLANG_LANGUAGE_NGINX       0.17      0.36      0.23        11\n",
      "TGLANG_LANGUAGE_OBJECTIVE_C       0.12      0.33      0.18         3\n",
      "        TGLANG_LANGUAGE_PHP       0.79      0.87      0.83        39\n",
      " TGLANG_LANGUAGE_POWERSHELL       0.04      0.50      0.07         8\n",
      "     TGLANG_LANGUAGE_PYTHON       0.62      0.71      0.66       222\n",
      "       TGLANG_LANGUAGE_RUBY       0.07      0.50      0.12         8\n",
      "       TGLANG_LANGUAGE_RUST       0.59      0.83      0.69        23\n",
      "      TGLANG_LANGUAGE_SHELL       0.44      0.68      0.54       164\n",
      "   TGLANG_LANGUAGE_SOLIDITY       0.37      0.79      0.50        14\n",
      "        TGLANG_LANGUAGE_SQL       0.47      0.88      0.61        24\n",
      "      TGLANG_LANGUAGE_SWIFT       0.08      1.00      0.15         2\n",
      "         TGLANG_LANGUAGE_TL       0.00      0.00      0.00         2\n",
      " TGLANG_LANGUAGE_TYPESCRIPT       0.31      0.52      0.39        21\n",
      "        TGLANG_LANGUAGE_XML       0.30      0.75      0.43         8\n",
      "\n",
      "                   accuracy                           0.92     11145\n",
      "                  macro avg       0.38      0.60      0.43     11145\n",
      "               weighted avg       0.96      0.92      0.94     11145\n",
      "\n",
      "balanced_accuracy_score 0.5979489622573149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "forest = get_baseline_score(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e40491c-75d9-473a-b96d-df5413306a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_score(X_train, y_train, X_test, y_test):\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    manual_best_params = {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"][3],\n",
    "        \"max_iter\": 1000\n",
    "    }\n",
    "\n",
    "    clf = OneVsRestClassifier(SVC(**manual_best_params))\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(f'Accuracy: {clf.score(X_test, y_test)}')\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"f1_score\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"precision_score\", precision_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(y_test, y_pred, average=\"macro\"))\n",
    "    print(classification_report(y_test, y_pred, target_names=tglang_names))\n",
    "    print(\"balanced_accuracy_score\", balanced_accuracy_score(y_test, y_pred))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a105c1b-d087-4424-8825-1d8edd1faa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44549125168236875\n",
      "f1_score 0.0664122763917314\n",
      "precision_score 0.1305131075068466\n",
      "recall_score 0.09915953996250028\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "      TGLANG_LANGUAGE_OTHER       0.96      0.48      0.64     10186\n",
      "          TGLANG_LANGUAGE_C       0.01      0.03      0.01        30\n",
      "  TGLANG_LANGUAGE_CPLUSPLUS       0.00      0.00      0.00        37\n",
      "     TGLANG_LANGUAGE_CSHARP       0.01      0.21      0.01        19\n",
      "        TGLANG_LANGUAGE_CSS       0.00      0.00      0.00        15\n",
      "       TGLANG_LANGUAGE_DART       0.00      0.00      0.00         7\n",
      "     TGLANG_LANGUAGE_DOCKER       0.17      0.09      0.12        11\n",
      "       TGLANG_LANGUAGE_FUNC       0.00      0.00      0.00         1\n",
      "         TGLANG_LANGUAGE_GO       0.01      0.11      0.01        19\n",
      "       TGLANG_LANGUAGE_HTML       0.00      0.00      0.00        32\n",
      "       TGLANG_LANGUAGE_JAVA       0.08      0.05      0.06       113\n",
      " TGLANG_LANGUAGE_JAVASCRIPT       0.00      0.00      0.00         7\n",
      "       TGLANG_LANGUAGE_JSON       0.07      0.30      0.11        81\n",
      "     TGLANG_LANGUAGE_KOTLIN       0.00      0.08      0.00        13\n",
      "        TGLANG_LANGUAGE_LUA       0.01      0.08      0.01        25\n",
      "      TGLANG_LANGUAGE_NGINX       1.00      0.09      0.17        11\n",
      "TGLANG_LANGUAGE_OBJECTIVE_C       0.00      0.00      0.00         3\n",
      "        TGLANG_LANGUAGE_PHP       0.53      0.23      0.32        39\n",
      " TGLANG_LANGUAGE_POWERSHELL       0.00      0.00      0.00         8\n",
      "     TGLANG_LANGUAGE_PYTHON       0.77      0.10      0.18       222\n",
      "       TGLANG_LANGUAGE_RUBY       0.11      0.25      0.15         8\n",
      "       TGLANG_LANGUAGE_RUST       0.06      0.17      0.09        23\n",
      "      TGLANG_LANGUAGE_SHELL       0.00      0.00      0.00       164\n",
      "   TGLANG_LANGUAGE_SOLIDITY       0.01      0.14      0.01        14\n",
      "        TGLANG_LANGUAGE_SQL       0.00      0.08      0.01        24\n",
      "      TGLANG_LANGUAGE_SWIFT       0.00      0.00      0.00         2\n",
      "         TGLANG_LANGUAGE_TL       0.00      0.00      0.00         2\n",
      " TGLANG_LANGUAGE_TYPESCRIPT       0.00      0.00      0.00        21\n",
      "        TGLANG_LANGUAGE_XML       0.00      0.38      0.00         8\n",
      "\n",
      "                   accuracy                           0.45     11145\n",
      "                  macro avg       0.13      0.10      0.07     11145\n",
      "               weighted avg       0.89      0.45      0.59     11145\n",
      "\n",
      "balanced_accuracy_score 0.09915953996250028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "code_svm = get_svm_score(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afd2ca14-1634-454e-abbd-50f95e6fe894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.8186356947656086\n",
    "# f1_score 0.7435253562514733\n",
    "# precision_score 0.7553975846316408\n",
    "# recall_score 0.7433261328760707\n",
    "#                              precision    recall  f1-score   support\n",
    "\n",
    "#       TGLANG_LANGUAGE_OTHER       0.96      0.94      0.95     11175\n",
    "#           TGLANG_LANGUAGE_C       0.55      0.64      0.59      1024\n",
    "#   TGLANG_LANGUAGE_CPLUSPLUS       0.73      0.59      0.65      1054\n",
    "#      TGLANG_LANGUAGE_CSHARP       0.80      0.79      0.80       955\n",
    "#         TGLANG_LANGUAGE_CSS       0.91      0.94      0.92      1028\n",
    "#        TGLANG_LANGUAGE_DART       0.81      0.65      0.72      1008\n",
    "#      TGLANG_LANGUAGE_DOCKER       0.91      0.89      0.90       930\n",
    "#        TGLANG_LANGUAGE_FUNC       0.00      0.00      0.00         5\n",
    "#          TGLANG_LANGUAGE_GO       0.75      0.85      0.80       990\n",
    "#        TGLANG_LANGUAGE_HTML       0.77      0.79      0.78      1038\n",
    "#        TGLANG_LANGUAGE_JAVA       0.61      0.69      0.65      1113\n",
    "#  TGLANG_LANGUAGE_JAVASCRIPT       0.56      0.43      0.49      1000\n",
    "#        TGLANG_LANGUAGE_JSON       0.81      0.94      0.87      1095\n",
    "#      TGLANG_LANGUAGE_KOTLIN       0.70      0.81      0.75      1023\n",
    "#         TGLANG_LANGUAGE_LUA       0.77      0.73      0.75      1033\n",
    "#       TGLANG_LANGUAGE_NGINX       0.92      0.91      0.92       780\n",
    "# TGLANG_LANGUAGE_OBJECTIVE_C       0.88      0.73      0.80       910\n",
    "#         TGLANG_LANGUAGE_PHP       0.90      0.79      0.84      1079\n",
    "#  TGLANG_LANGUAGE_POWERSHELL       0.75      0.85      0.80       996\n",
    "#      TGLANG_LANGUAGE_PYTHON       0.62      0.77      0.68      1219\n",
    "#        TGLANG_LANGUAGE_RUBY       0.76      0.80      0.78      1029\n",
    "#        TGLANG_LANGUAGE_RUST       0.88      0.82      0.85      1013\n",
    "#       TGLANG_LANGUAGE_SHELL       0.66      0.83      0.73      1170\n",
    "#    TGLANG_LANGUAGE_SOLIDITY       0.86      0.81      0.83      1014\n",
    "#         TGLANG_LANGUAGE_SQL       0.84      0.82      0.83      1006\n",
    "#       TGLANG_LANGUAGE_SWIFT       0.71      0.82      0.76      1036\n",
    "#          TGLANG_LANGUAGE_TL       0.99      0.53      0.69       365\n",
    "#  TGLANG_LANGUAGE_TYPESCRIPT       0.68      0.49      0.57       980\n",
    "#         TGLANG_LANGUAGE_XML       0.82      0.90      0.86       988\n",
    "\n",
    "#                    accuracy                           0.82     38056\n",
    "#                   macro avg       0.76      0.74      0.74     38056\n",
    "#                weighted avg       0.82      0.82      0.82     38056\n",
    "\n",
    "# balanced_accuracy_score 0.7433261328760707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64735621-9609-4979-a7f2-c10ed0741eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a30dae32-3fb3-45d2-a725-ec66d7168afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM.pkl\n",
      "accuracy 0.9483176312247644\n",
      "f1_score 0.4734345983654528\n",
      "precision_score 0.4423915969090338\n",
      "recall_score 0.5833540716033445\n",
      "balanced_accuracy_score 0.5833540716033445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_careful.pkl\n",
      "accuracy 0.9341408703454464\n",
      "f1_score 0.4437925199236539\n",
      "precision_score 0.3977162876574334\n",
      "recall_score 0.5915369456876967\n",
      "balanced_accuracy_score 0.5915369456876967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_careless.pkl\n",
      "accuracy 0.9509196949304621\n",
      "f1_score 0.47844339271927566\n",
      "precision_score 0.45671177580469213\n",
      "recall_score 0.5647219287201618\n",
      "balanced_accuracy_score 0.5647219287201618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_too_careful.pkl\n",
      "accuracy 0.9286675639300135\n",
      "f1_score 0.43840430195226\n",
      "precision_score 0.3889259887909439\n",
      "recall_score 0.595418121244119\n",
      "balanced_accuracy_score 0.595418121244119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_equal.pkl\n",
      "accuracy 0.9530731269627636\n",
      "f1_score 0.4753050721007133\n",
      "precision_score 0.48771612789727314\n",
      "recall_score 0.5169294479218013\n",
      "balanced_accuracy_score 0.5169294479218013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_path   = Path(\"../dataset_v1/data/model/SVM.pkl\")\n",
    "\n",
    "for svm_path in [\n",
    "    \"../dataset_v1/data/model/SVM.pkl\",\n",
    "    \"../dataset_v1/data/model/SVM_careful.pkl\",\n",
    "    \"../dataset_v1/data/model/SVM_careless.pkl\",\n",
    "    \"../dataset_v1/data/model/SVM_too_careful.pkl\",\n",
    "    \"../dataset_v1/data/model/SVM_equal.pkl\",\n",
    "]:\n",
    "    svm = joblib.load(svm_path)\n",
    "    models_predict = forest.predict(X_test) * svm.predict(X_test_svm)\n",
    "\n",
    "    print(svm_path.split(\"/\")[-1])\n",
    "    print(\"accuracy\", accuracy_score(y_test, models_predict))\n",
    "    print(\"f1_score\", f1_score(y_test, models_predict, average=\"macro\"))\n",
    "    print(\"precision_score\", precision_score(y_test, models_predict, average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(y_test, models_predict, average=\"macro\"))\n",
    "    # print(classification_report(y_test, models_predict, target_names=tglang_names))\n",
    "    print(\"balanced_accuracy_score\", balanced_accuracy_score(y_test, models_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73e1800b-21c6-4e52-a7fc-2d7ab8f26e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidfi.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(forest, \"forest.pkl\")\n",
    "joblib.dump(tfidf, \"tfidfi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01e11dee-5c43-45f4-a012-e17c1f10967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.8375551818372924\n",
    "# f1_score 0.7643238669957512\n",
    "# precision_score 0.7719059282201296\n",
    "# recall_score 0.7642280574677937\n",
    "#                              precision    recall  f1-score   support\n",
    "\n",
    "#       TGLANG_LANGUAGE_OTHER       0.98      0.95      0.96     11175\n",
    "#           TGLANG_LANGUAGE_C       0.55      0.67      0.61      1024\n",
    "#   TGLANG_LANGUAGE_CPLUSPLUS       0.70      0.60      0.65      1054\n",
    "#      TGLANG_LANGUAGE_CSHARP       0.82      0.82      0.82       955\n",
    "#         TGLANG_LANGUAGE_CSS       0.92      0.95      0.93      1028\n",
    "#        TGLANG_LANGUAGE_DART       0.82      0.71      0.76      1008\n",
    "#      TGLANG_LANGUAGE_DOCKER       0.92      0.90      0.91       930\n",
    "#        TGLANG_LANGUAGE_FUNC       0.00      0.00      0.00         5\n",
    "#          TGLANG_LANGUAGE_GO       0.79      0.87      0.83       990\n",
    "#        TGLANG_LANGUAGE_HTML       0.78      0.81      0.79      1038\n",
    "#        TGLANG_LANGUAGE_JAVA       0.68      0.68      0.68      1113\n",
    "#  TGLANG_LANGUAGE_JAVASCRIPT       0.56      0.47      0.51      1000\n",
    "#        TGLANG_LANGUAGE_JSON       0.84      0.94      0.88      1095\n",
    "#      TGLANG_LANGUAGE_KOTLIN       0.77      0.82      0.79      1023\n",
    "#         TGLANG_LANGUAGE_LUA       0.76      0.78      0.77      1033\n",
    "#       TGLANG_LANGUAGE_NGINX       0.94      0.92      0.93       780\n",
    "# TGLANG_LANGUAGE_OBJECTIVE_C       0.89      0.75      0.82       910\n",
    "#         TGLANG_LANGUAGE_PHP       0.90      0.80      0.85      1079\n",
    "#  TGLANG_LANGUAGE_POWERSHELL       0.79      0.87      0.83       996\n",
    "#      TGLANG_LANGUAGE_PYTHON       0.67      0.78      0.72      1219\n",
    "#        TGLANG_LANGUAGE_RUBY       0.79      0.82      0.80      1029\n",
    "#        TGLANG_LANGUAGE_RUST       0.88      0.84      0.86      1013\n",
    "#       TGLANG_LANGUAGE_SHELL       0.70      0.86      0.77      1170\n",
    "#    TGLANG_LANGUAGE_SOLIDITY       0.85      0.83      0.84      1014\n",
    "#         TGLANG_LANGUAGE_SQL       0.84      0.85      0.84      1006\n",
    "#       TGLANG_LANGUAGE_SWIFT       0.79      0.84      0.81      1036\n",
    "#          TGLANG_LANGUAGE_TL       0.97      0.58      0.72       365\n",
    "#  TGLANG_LANGUAGE_TYPESCRIPT       0.68      0.54      0.60       980\n",
    "#         TGLANG_LANGUAGE_XML       0.85      0.90      0.88       988\n",
    "\n",
    "#                    accuracy                           0.84     38056\n",
    "#                   macro avg       0.77      0.76      0.76     38056\n",
    "#                weighted avg       0.84      0.84      0.84     38056\n",
    "\n",
    "# balanced_accuracy_score 0.7642280574677937\n",
    "\n",
    "# SVM.pkl\n",
    "# accuracy 0.7908608366617617\n",
    "# f1_score 0.7295919733940959\n",
    "# precision_score 0.7828005765033781\n",
    "# recall_score 0.692997430579706\n",
    "# balanced_accuracy_score 0.692997430579706\n",
    "# /Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "#   _warn_prf(average, modifier, msg_start, len(result))\n",
    "# SVM_careful.pkl\n",
    "# accuracy 0.8244166491486231\n",
    "# f1_score 0.7547543831899822\n",
    "# precision_score 0.7735080351001856\n",
    "# recall_score 0.7443816122630108\n",
    "# balanced_accuracy_score 0.7443816122630108\n",
    "# /Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "#   _warn_prf(average, modifier, msg_start, len(result))\n",
    "# SVM_careless.pkl\n",
    "# accuracy 0.7620086188774438\n",
    "# f1_score 0.7022615903269126\n",
    "# precision_score 0.7838848341302994\n",
    "# recall_score 0.6501080387531972\n",
    "# balanced_accuracy_score 0.6501080387531972\n",
    "# /Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "#   _warn_prf(average, modifier, msg_start, len(result))\n",
    "# SVM_too_careful.pkl\n",
    "# accuracy 0.8295932310279588\n",
    "# f1_score 0.7584515377198469\n",
    "# precision_score 0.7722386497009159\n",
    "# recall_score 0.7525468119791242\n",
    "# balanced_accuracy_score 0.7525468119791242\n",
    "# /Users/platon.fedorov/opt/anaconda3/envs/tgml/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "#   _warn_prf(average, modifier, msg_start, len(result))\n",
    "# SVM_equal.pkl\n",
    "# accuracy 0.7044881227664495\n",
    "# f1_score 0.6474534257622541\n",
    "# precision_score 0.7859921528115783\n",
    "# recall_score 0.5708234518178323\n",
    "# balanced_accuracy_score 0.5708234518178323"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
